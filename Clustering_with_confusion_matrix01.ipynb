{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import EMG Dataset\n",
    "X = np.genfromtxt('traing_matrix05.csv', delimiter=',', skip_header=2)\n",
    "X1 = np.genfromtxt('test_matrix05.csv', delimiter=',', skip_header=2)\n",
    "\n",
    "m,n = np.shape(X)\n",
    "\n",
    "x_train = []\n",
    "y_train = [] \n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "#Split data x_train, y_train\n",
    "x_train = X[:,0:n-7]\n",
    "y_train = X[:,65:71]\n",
    "\n",
    "\n",
    "#Test data \n",
    "x_test = X1[:,0:n-7]\n",
    "y_test = X1[:,65:71]\n",
    "\n",
    "y_class_test=X1[:,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 64)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clus=6\n",
    "#cluster=[]\n",
    "clusters=[]\n",
    "cx1=[]\n",
    "cy1=[]\n",
    "\n",
    "for f in range(len(x_test)):\n",
    "    #cluster.append([])\n",
    "    cx1.append([])\n",
    "    cy1.append([])\n",
    "    clusters.append([])\n",
    "    xx1_train=np.vstack((x_train,x_test[f,:]))\n",
    "    cluster = AgglomerativeClustering(n_clusters=clus, affinity='euclidean', linkage='ward')\n",
    "    clusters[f]=cluster.fit_predict(xx1_train)\n",
    "\n",
    "\n",
    "    for i in range (0,clus):\n",
    "        cx1[f].append([])\n",
    "        cy1[f].append([])\n",
    "        h=0\n",
    "        for j in range (len(clusters[f])-1):\n",
    "            \n",
    "            if clusters[f][j]==i:\n",
    "                cx1[f][i].append([])\n",
    "                cy1[f][i].append([])\n",
    "                cx1[f][i][h]=x_train[j,:]\n",
    "                cy1[f][i][h]=y_train[j,:]\n",
    "                h=h+1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(cy1[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1=[]\n",
    "for f in range(len(x_test)):\n",
    "    prob1.append([])\n",
    "    for i in range (0, clus):\n",
    "        prob1[f].append([])\n",
    "        prob1[f][i]= np.sum(cy1[f][i],axis=0)/np.sum(np.sum(cy1[f][i],axis=0),axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_prob1=[]\n",
    "cy_pred=[]\n",
    "cy1_binary=[]\n",
    "\n",
    "for f in range(len(x_test)):\n",
    "    cy_prob1.append([])\n",
    "    cy1_binary.append([])\n",
    "    c_train=clusters[f][-1]\n",
    "    cy_prob1[f]=prob1[f][c_train]\n",
    "    \n",
    "    \n",
    "    for i in range (0,clus):\n",
    "        cy1_binary[f].append([])\n",
    "        cy1_binary[f][i]=[1 if x == max(prob1[f][i]) else 0 for x in prob1[f][i]]\n",
    "        \n",
    "        \n",
    "       # for j in range (len(clusters[f])-1):\n",
    "#check for any of equal probability\n",
    "db=[]\n",
    "for f in range (len(x_test)):\n",
    "    cy_pred.append([])\n",
    "    c_train=clusters[f][-1]\n",
    "    cy_pred[f]=cy1_binary[f][c_train]\n",
    "    if np.sum(cy1_binary[f]) != 6:\n",
    "        db.append([f])\n",
    "        \n",
    "#db = 117 and 170 have double probability\n",
    "cy1_binary[117][5][3]=0\n",
    "cy1_binary[170][3][3]=0\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[ 0.  0. -1.  1.  0.  0.]\n",
      "1440\n",
      "[0.07246377 0.72463768 0.05797101 0.04347826 0.04347826 0.05797101]\n",
      "[[117], [170]]\n",
      "[[0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(cy_pred[0]))\n",
    "print(y_test[0])\n",
    "print(cy_pred[200]-y_test[200])\n",
    "print(np.sum(cy1_binary))\n",
    "\n",
    "print(prob1[0][4])\n",
    "print(db)\n",
    "print(cy1_binary[170])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=[]\n",
    "error=0\n",
    "for f in range(len(x_test)):\n",
    "    mat.append([])\n",
    "    \n",
    "    for i in range (0,6):\n",
    "        mat[f].append([])\n",
    "        mat[f][i]=y_test[f][i]-cy_pred[f][i]\n",
    "        if mat[f][i] != 0:\n",
    "            error=error+1\n",
    "error=error/2/len(y_test)  #divide by two because every miss increases error by 2\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n",
      "0\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "print(error)\n",
    "print(miss)\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion Matrix\n",
    "confu=np.zeros([6,6])\n",
    "for f in range (len(x_test)):\n",
    "    \n",
    "    for i in range (0,6):\n",
    "        \n",
    "        for j in range (0,6):\n",
    "            if mat[f][j]==-1:\n",
    "                if mat[f][i]==1:\n",
    "                    confu[i][j]=confu[i][j]+1\n",
    "for f in range (len(x_test)):\n",
    "    for j in range (0,6):\n",
    "        if y_test[f][j]==1:\n",
    "            if cy_pred[f][j]==1:\n",
    "                confu[j][j]=confu[j][j]+1\n",
    "confu_per=np.around((confu/(len(y_test)/6)*100),decimals=2) #confusion matrix in percentage\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.  2.  1.  5.  0.  3.]\n",
      " [ 4.  9. 24.  2.  0.  1.]\n",
      " [ 0.  1.  9. 29.  1.  0.]\n",
      " [ 1.  0.  2. 36.  1.  0.]\n",
      " [ 0.  1.  8. 11.  0. 20.]\n",
      " [ 0.  1. 11.  3.  0. 25.]]\n",
      "-------------------------------\n",
      "[[72.5  5.   2.5 12.5  0.   7.5]\n",
      " [10.  22.5 60.   5.   0.   2.5]\n",
      " [ 0.   2.5 22.5 72.5  2.5  0. ]\n",
      " [ 2.5  0.   5.  90.   2.5  0. ]\n",
      " [ 0.   2.5 20.  27.5  0.  50. ]\n",
      " [ 0.   2.5 27.5  7.5  0.  62.5]]\n"
     ]
    }
   ],
   "source": [
    "print(confu)\n",
    "print('-------------------------------')\n",
    "print(confu_per)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-248-78dfe8495a3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcy_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'0'\u001b[0m \u001b[1;34m'1'\u001b[0m \u001b[1;34m'2'\u001b[0m \u001b[1;34m'3'\u001b[0m \u001b[1;34m'4'\u001b[0m \u001b[1;34m'5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Normalized confusion matrix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-235-894dc6e3e395>\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(y_true, y_pred, classes, normalize, title, cmap)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Compute confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Only use the labels that appear in the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass-multioutput targets"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(y_test, cy_pred, classes=['0' '1' '2' '3' '4' '5'],normalize=True, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
